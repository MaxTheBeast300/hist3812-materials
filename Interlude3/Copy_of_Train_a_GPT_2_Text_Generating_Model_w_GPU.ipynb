{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: October 17th, 2021*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read my [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_"
      },
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1381cc-80d8-4fda-e6ac-9c88ff2055fe"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 16 19:05:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    27W /  70W |  14228MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af1c4f3-0cae-46c3-f5a3-570bc4bbe63e"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 387Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:02, 514kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 395Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:21, 6.12Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 387Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:01, 857kit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:01, 732kit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"MozartRTD.txt\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607b61f8-1b69-4510-9d92-97ee31a4e6e2"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=400,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=400\n",
        "              )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 426368 tokens\n",
            "Training...\n",
            "[10 | 24.91] loss=3.47 avg=3.47\n",
            "[20 | 46.03] loss=3.42 avg=3.44\n",
            "[30 | 67.43] loss=3.30 avg=3.39\n",
            "[40 | 89.03] loss=3.13 avg=3.33\n",
            "[50 | 110.91] loss=3.04 avg=3.27\n",
            "[60 | 133.00] loss=3.05 avg=3.23\n",
            "[70 | 155.22] loss=3.11 avg=3.21\n",
            "[80 | 177.60] loss=3.04 avg=3.19\n",
            "[90 | 200.17] loss=3.18 avg=3.19\n",
            "[100 | 222.85] loss=2.82 avg=3.15\n",
            "[110 | 245.57] loss=2.96 avg=3.13\n",
            "[120 | 268.41] loss=2.89 avg=3.11\n",
            "[130 | 291.42] loss=2.48 avg=3.06\n",
            "[140 | 314.52] loss=3.00 avg=3.06\n",
            "[150 | 337.63] loss=2.53 avg=3.02\n",
            "[160 | 360.74] loss=3.16 avg=3.03\n",
            "[170 | 383.89] loss=2.75 avg=3.01\n",
            "[180 | 407.03] loss=2.34 avg=2.97\n",
            "[190 | 430.15] loss=2.90 avg=2.97\n",
            "[200 | 453.27] loss=2.66 avg=2.95\n",
            "======== SAMPLE 1 ========\n",
            " and we have a greater\n",
            "knowledge of the state of the art than ever possible before, we shall write\n",
            "additional remarks at a later time, but this will give the reader\n",
            "more leeway\n",
            "\n",
            "The following are remarks on the last lines:--\n",
            "\n",
            "   Madame Vaucluse, you seem to me like a person entirely\n",
            "   without an intention;--I have known you for forty-four hours.\n",
            "   How would you feel if I told you that yesterday I played\n",
            "   and played, and also yesterday I played, at least, in one\n",
            "   room, for the pleasure of Madame Viardot et her children.\n",
            "   If you think I am unkind, perhaps you are dreaming; but,\n",
            "   be true, I have a strong sympathy with you because, at\n",
            "   the same time, I feel certain that in the evening I\n",
            "   will do the same.\n",
            "\n",
            "I do not wish to deprive you, therefore, of my opportunity to ask the\n",
            "question. \"Madame Vaucluse?\" you may say what you desire. A lady who\n",
            "acquires a thorough knowledge of the pianoforte but not much of\n",
            "the piano, has already asked me for my opinion. \"It is a mystery\n",
            "of the very instrument to me, that I am still born--and I am a\n",
            "mere infant, being born in the neighbourhood of the country,\" she said.\n",
            "Now, it is not only possible to get knowledge without leaving a\n",
            "little too much to be desired, it is also also possible. Chopin told me, for\n",
            "instance, that he had played very often his old master's works in the\n",
            "composi-terre, and his own compositions. But the words he\n",
            "said about a friend and acquaintance having played to him his favourite\n",
            "pieces did not apply to Liszt himself. \"Chopin must have played\n",
            "to me in my salon,\" he wrote. \"I think only after you played and\n",
            "stood in one room.\"\n",
            "\n",
            "I have also the honour to inform you that Chopin, with his own words,\n",
            "played again at his own concerts on the last night of November\n",
            "4, 1828, and on the occasion of the commencement of this year's\n",
            "Opus Vivaldi.\n",
            "\n",
            "   [FOOTNOTE: The question from which in the above-quoted\n",
            "note I make myself \"quicker than in a second\" is a question that will\n",
            "soon find its place in the new edition of the Conservatoire. Although\n",
            "it is not yet finished, I hope you shall forgive me a few quid\n",
            "pence. I must now turn the most important of all the preceding\n",
            "quotation-descriptions into the most instructive. The question,\n",
            "according to Chopin, began with a question. What are the effects of\n",
            "a beautiful first section? What is the effect of a dry and light\n",
            "first section?\n",
            "\n",
            "The effects of what is called a little last section, which he uses\n",
            "for his playing, are somewhat unlike those that he uses for his\n",
            "playing. I must also inform you that this last section, which\n",
            "Chopin calls \"piano spp.\", is sometimes called \"piano spp. m.\"\n",
            "And in the Polish spelling \"soprano\" refers only to the pianoforte\n",
            "or to the orchestra. \"It ought to be called soprano,\" he says, with\n",
            "a smile. \"It is not a pretty rendering of the former.\"\n",
            "That the sine and cosine do not equal one and the same\n",
            "sine and cosine, that a little last section is more lively\n",
            "than it ought to, and that one may sing better with it than not\n",
            "with it altogether, makes them really close friends whom he plays so\n",
            "gently and tenderly. But to what end will I descend with his questions?\n",
            "[FOOTNOTE: There is indeed a question at the end of this paper (July 7,\n",
            "1829?) whose date is probably not correct. But it has been\n",
            "put out by George Sand, who has given Chopin some very interesting answers concerning\n",
            "this curious musical event. [FOOTNOTE: George Sand.] Chopin, I\n",
            "think, was at first somewhat startled when, when reading this, he suddenly\n",
            "noticed the last section--\"soprano.\" This last section was what he thought\n",
            "was the first section in his \"piano spp.\" This section is called from one of\n",
            "Chopin's pieces, La soprano. The word \"soprano,\" which can only mean\n",
            "soprano, was derived from the former meaning \"sorrowful,\" and would\n",
            "have been more correct, but for a less expressive and tender tone,\n",
            "namely, of the first section, \"sparks.\"\n",
            "\n",
            "In a letter addressed to his friend Sowinski, Chopin remarks that, unlike\n",
            "M\n",
            "\n",
            "[210 | 490.23] loss=2.74 avg=2.94\n",
            "[220 | 513.44] loss=2.72 avg=2.93\n",
            "[230 | 536.60] loss=2.62 avg=2.91\n",
            "[240 | 559.71] loss=2.50 avg=2.89\n",
            "[250 | 582.81] loss=2.41 avg=2.87\n",
            "[260 | 605.94] loss=2.57 avg=2.86\n",
            "[270 | 629.04] loss=2.23 avg=2.83\n",
            "[280 | 652.12] loss=2.31 avg=2.81\n",
            "[290 | 675.27] loss=2.61 avg=2.80\n",
            "[300 | 698.47] loss=2.65 avg=2.80\n",
            "[310 | 721.62] loss=2.49 avg=2.78\n",
            "[320 | 744.72] loss=2.40 avg=2.77\n",
            "[330 | 767.83] loss=2.22 avg=2.75\n",
            "[340 | 790.97] loss=2.35 avg=2.74\n",
            "[350 | 814.16] loss=2.41 avg=2.73\n",
            "[360 | 837.36] loss=2.21 avg=2.71\n",
            "[370 | 860.50] loss=2.51 avg=2.70\n",
            "[380 | 883.61] loss=2.58 avg=2.70\n",
            "[390 | 906.73] loss=1.85 avg=2.67\n",
            "[400 | 929.82] loss=2.14 avg=2.66\n",
            "Saving checkpoint/run1/model-400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8938432a-3b86-4102-f32b-362721ecb897"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "353132bd-e248-470f-f9f1-75823e337d2a"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Open House of the Polish National\n",
            "Parishioners, of which the reader will hear more in the\n",
            "chapter entitled \"Archaeological Findings and the Present State of\n",
            "Polish Folk-lore,\" will have a part in the programme. An advert on the\n",
            "same day, on October 22, 1816, in the \"Correspondance,\" gives a fuller\n",
            "description of the proceedings. The programme includes the following remarks:--\n",
            "\n",
            "PRAGUE--Arguments and debates about Poland and the national\n",
            "heroic character of the Poles are at the present time an ever\n",
            "great novelty to Poland. The national character of Poland, which originated\n",
            "as a nation, is now soon in the hands of the national imagination. The\n",
            "national character of Poland is in this respect an inexhaustible gutter, and\n",
            "it is evident that there is not a whit of truth in the patriotic creed which\n",
            "cannot be fully summed up in a phrase which describes the national character of\n",
            "Poland: \"And now, the national heroes, the national heroes of Europe, we\n",
            "disappointed ourselves with the Polish national heroes, our heroic national heroes,\n",
            "who have now taken up their quarters in the monastery of Warsaw and in\n",
            "the bosom of the Pyrenees.\" By a word of the name of the national\n",
            "hero, the national character of Poland is now in its homeliest\n",
            "individual form, and its national history, national culture, and\n",
            "national character are, in short, in this respect fully developed and\n",
            "progressing.\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER XXII\n",
            "\n",
            "\n",
            "\n",
            "HIS FIRST VISIT TO PRAGUE IN 1816.--PLEASING OF CHOPIN TO ROMANTICIANS;\n",
            "REMINISCENCES COUNTS IN COMMENCEMENT OF POLISH\n",
            "LITERALISM.--HIS FIRST VISIT TO PRAGUE IN THE FASHIONABLE MYSELF.\n",
            "\n",
            "\n",
            "\n",
            "The first introduction to our chapter concerned with Chopin's\n",
            "first visit to Poland, and was passed with his consent and\n",
            "consent to by the Polish nobility, we have already seen. His\n",
            "admission was on March 25, 1816, and the following month was the first\n",
            "time that he had been heard in public. The musical life there\n",
            "was not confined to Poland, in fact the tastes, customs, and\n",
            "cultures of the people there were much more varied.\n",
            "The peasantry of Warsaw, to whom the character of Poland\n",
            "contributed greatly, had gained a new insight into the people and\n",
            "society there, and was then in a favourable position to rise to a\n",
            "new stage of development. From the first to the end of the eighteenth\n",
            "century Poland was divided into three branches: the military,\n",
            "civil, and religious. The military, which in 1807 was given\n",
            "or assumed the name of Poland (prussian), was the principal military\n",
            "part of the national national character. The civil service was the\n",
            "execution of a king, or rather of a select circle of princes,\n",
            "appointed by the king to perform the civil duties of the government,\n",
            "and to discharge the duties of executing the laws and executing\n",
            "the laws of the country. Academists and other non-academists,\n",
            "in general and especially in their various social and political parties,\n",
            "had a great influence on the military service of Poland. The national\n",
            "classifications of the various branches of the social and political\n",
            "institutions were, therefore, based on the same principle of inequality of\n",
            "power and inequality of privileges that existed in the nations at large.\n",
            "This inequality of power and privilege, however, was not the\n",
            "exclusive cause of the inequality of wealth and privilege. In fact, the\n",
            "national character of Poland, as has been stated, was not much altered by\n",
            "the partition of Poland into two states (the former being now the Prussian\n",
            "Republic, the latter being now Poland) and the union of two peoples.\n",
            "The nobility, on the other hand, was endowed with a right, which had\n",
            "originally nothing to do with equality of wealth, but with equality of\n",
            "privacy. The nobility of Poland possessed, as we have already seen, the\n",
            "predestined judge, priest, and legate, the guard and the soldier, the\n",
            "parliamentary officer, the steward, and the marshal, the ministers,\n",
            "and the burghers, the burgesses, and the fishers, the peasants, and\n",
            "the free craftsmen, the fishers, and the fishers-trees. The commonalty,\n",
            "in short, was superior to the burgesses and peasants, the maker of\n",
            "the laws and the steward and artist, the king, and the marshal and\n",
            "constable. But the nobility of Poland was not inferior to the\n",
            "public, it had become a nation. For the most part the nobility had\n",
            "to do with the administration of public buildings and their erection; but in\n",
            "fact it was chiefly with the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8550f5-4d89-4813-9ec3-b987c1567f76"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"I ask myself, what is music?\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I ask myself, what is music?\n",
            "   I am a musician, and I do not know music.\n",
            "   I have a preference for the latter, for he who studies it\n",
            "   becomes poet, and for him who does not study it becomes\n",
            "   poet. It is not my business to teach him music. I\n",
            "   shall write to you in no particular what I study. It is\n",
            "   for this reason that I have a name for it; for I do not\n",
            "   wish to annoy you, but you do not like the name.\n",
            "\n",
            "   Be it known to any one who calls himself a musician, I will\n",
            "   play you my compositions.\n",
            "\n",
            "\n",
            "   Tuesday, May 25, 1838.\n",
            "\n",
            "   I send you my Concerto by Chopin, for September 2,\n",
            "   and October 1st.\n",
            "\n",
            "   Yesterday I received your letter. I sent you a\n",
            "   letter; but a letter from Nohant would be wiser.\n",
            "\n",
            "   The concert will take place in your Square on Monday, September\n",
            "   and take place in the Square opposite the Theatre.\n",
            "\n",
            "   I send you the Prelude, for September 2nd, and the Prelude from\n",
            "\n",
            "====================\n",
            "I ask myself, what is music? Is it not the voice of the conscious mind, the\n",
            "knowledge and insight of one's self, which is transmitted to the\n",
            "mind, and the expression of the unconscious, which, as regards the\n",
            "mind, is at once conscious and unconscious? I have not the time to\n",
            "discuss the question here, but I shall at least give an account of it in\n",
            "a subsequent chapter.\n",
            "\n",
            "The most important development of Chopin's style of life was his\n",
            "movement in the second decade of the year 1828. In 1828, at a\n",
            "concert given by Bellini, he showed himself at once at the close of the\n",
            "concert a new man, and before long he was already a man of the world.\n",
            "But almost three years after his appearance at the concert, and the\n",
            "concert was over, Chopin had not yet left the cloister of the\n",
            "Empire, and had not he not left his home in Warsaw, he would not\n",
            "have remained at home for long. The following year he was again\n",
            "delighted at his departure; and, on September 20, 1829, he made his\n",
            "departure at nine o'clock in the morning. In the evening the young\n",
            "p\n",
            "====================\n",
            "I ask myself, what is music?\n",
            "  [FOOTNOTE: Leibgeber, the pianoforte-playing god, who is said to be a\n",
            "  lady of the house.] I am obliged to regard as a lady my\n",
            "  profession the most intimate circle of friends and lovers,\n",
            "  whom I employ in the greatest degree as instruments, and employ\n",
            "  myself more and more in the fulfilment of my intention.\n",
            "\n",
            "I have sometimes to confess the wish to make the reader see and feel\n",
            "himself. I am not the most estimable of men, but I am also\n",
            "not an excellent one. [FOOTNOTE: Thomas Carlyle.]\n",
            "\n",
            "If we look in the newspapers, we find that Chopin taught at\n",
            "the Conservatoire, and that he is said to have performed in 1841 many\n",
            "concertos (see the notice in the Musical World of September 1, 1840; and\n",
            "the concerto in the same year at Dresden.] No sooner had the\n",
            "composer passed the four years which spring of 1841 than he began\n",
            "to seriously consider the possibility of becoming a pianist. In a letter to\n",
            "me he writes that he had been asked to go to the Conservatoire, but that\n",
            "====================\n",
            "I ask myself, what is music? I begin to feel it from the depths of my heart.\n",
            "\n",
            "  When I am not feeling music, I am striving for it.\n",
            "\n",
            "  I am the highest creature in the world. I have no room for others.\n",
            "\n",
            "  I am the ablest soul in the world. I have no room for others.\n",
            "\n",
            "  I have no independence. I am nothing, and I am therefore nothing.\n",
            "\n",
            "  I am an animal.\n",
            "\n",
            "  I have no individuality.\n",
            "\n",
            "  I am the incomparable.\n",
            "\n",
            "  I have no individuality which can be compared to his\n",
            "\n",
            "  personality. He is like a serpent that is devoured.\n",
            "\n",
            "  I have no individuality which can be compared to the soul and\n",
            "  body of Chopin, and that is the supreme end of my existence.\n",
            "\n",
            "  I have no individuality which can be compared to the strength of\n",
            "  the man...I am nothing, and I am therefore nothing.\n",
            "\n",
            "  I am a being in the most perfect form.\n",
            "\n",
            "\n",
            "The Polish musician Gyrowetz, who had in 1835 published the Sonata in D flat minor of\n",
            "his concerto, Op. 4, in print as Op. 15, says:--\n",
            "\n",
            "  I have no individuality which\n",
            "====================\n",
            "I ask myself, what is music? Love me,\n",
            "mendocino! [This, perhaps, is the only theme in Mendelssohn's\n",
            "\"Les amours de ma Vie\"; it represents the love which the reader\n",
            "gives his friend.] But what is music? It is the most sublime and\n",
            "esthetical feeling imaginable.\n",
            "\n",
            "  Indeed, I have no idea what music is, except that it\n",
            "  manifests itself in the most sublime and most unutterably\n",
            "  sublime manner imaginable. [FOOTNOTE: Liszt, at once a\n",
            "  man of his word in this respect, and in his criticism, as well\n",
            "  as a man of his word in that, is the man who most fully describes\n",
            "  his admiration for Mendelssohn's music, and, rendering his\n",
            "  own compositions incomparably beautiful, declares, without\n",
            "  hesitation, the great master to be the first to describe the\n",
            "  nature of the music of Mendelssohn. He is not a pianist, but\n",
            "  a musician in the sense of a composer in the strictest sense of\n",
            "  \"permanent musical expression.\"] What is music? It is the\n",
            "  most extraordinary feeling imaginable.\n",
            "\n",
            "The reader will\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1591452c-d207-4c43-c348-e846f55df2ff"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0646201e-af4d-4b0c-8e54-d85d945f10df\", \"gpt2_gentext_20221116_185714.txt\", 184900)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n",
        "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
        "\n",
        "This is currently the only way to generate text from the 774M or 1558M models with this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "4e0c8a3f-3527-41c4-e3fe-3357f3f8f6c2"
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 354Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 131Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 279Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:23, 131Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 380Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 226Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 199Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 18:37:58.571830 139905369159552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "56348e28-7d08-45e3-c859-f26c0efd066d"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The secret of life is that it's really easy to make it complicated,\" said Bill Nye, the host of the popular science show \"Bill Nye the Science Guy.\" \"And this is one of the reasons why we all need to be smarter about science, because we can't keep up with the amazing things that are going on all the time.\"\n",
            "\n",
            "While Nye is correct that \"everything that's going on all the time\" is making the world a better place, he misses the point. This is not\n",
            "====================\n",
            "The secret of life is in the rhythm of the universe. It's not a mystery. It's not a mystery to me. It's the nature of the universe. It's the beauty of the universe. It's the way the universe works. It's the way the universe is. It's the way the universe is going to work. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way\n",
            "====================\n",
            "The secret of life is in the universe.\n",
            "\n",
            "\n",
            "-\n",
            "\n",
            "The Red Devil\n",
            "\n",
            "It's the end of the world as we know it, and the only thing that can save us is a band of super-powered individuals known as the Red Devil.\n",
            "\n",
            "\n",
            "The Red Devil is a group of super-powered individuals who are seeking the secret of life and the only way they know how to do it is by taking on the roles of a variety of different super-powered individuals, each of which has their own\n",
            "====================\n",
            "The secret of life is in the mixing of the elements, and it is the mixing of the elements that makes life possible.\"\n",
            "\n",
            "But in the world of food science, the idea of a \"complex\" or \"complexity\" is almost entirely imaginary.\n",
            "\n",
            "As a scientist, I'm fascinated by the question of how life first began.\n",
            "\n",
            "It's the question that drives my work and the work of the scientists who work on it.\n",
            "\n",
            "My current research is exploring how microbes work in the first moments\n",
            "====================\n",
            "The secret of life is the journey of life, the search for the truth.\n",
            "\n",
            "4.4.2. The last thing you know\n",
            "\n",
            "There is nothing more important than the last thing you know.\n",
            "\n",
            "4.4.3. The little things that make all the difference\n",
            "\n",
            "The little things that make all the difference.\n",
            "\n",
            "4.4.4. The truth is the best teacher\n",
            "\n",
            "The truth is the best teacher.\n",
            "\n",
            "4.4.5. The truth is what\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}